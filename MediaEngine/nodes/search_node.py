"""Search node implementation
Responsible for generating search queries and reflection queries"""

import json
from typing import Dict, Any
from json.decoder import JSONDecodeError
from loguru import logger

from .base_node import BaseNode
from ..prompts import SYSTEM_PROMPT_FIRST_SEARCH, SYSTEM_PROMPT_REFLECTION
from ..utils.text_processing import (
    remove_reasoning_from_output,
    clean_json_tags,
    extract_clean_response,
    fix_incomplete_json
)


class FirstSearchNode(BaseNode):
    """Node that generates the first search query for the paragraph"""
    
    def __init__(self, llm_client):
        """Initialize the first search node
        
        Args:
            llm_client: LLM client"""
        super().__init__(llm_client, "FirstSearchNode")
    
    def validate_input(self, input_data: Any) -> bool:
        """Validate input data"""
        if isinstance(input_data, str):
            try:
                data = json.loads(input_data)
                return "title" in data and "content" in data
            except JSONDecodeError:
                return False
        elif isinstance(input_data, dict):
            return "title" in input_data and "content" in input_data
        return False
    
    def run(self, input_data: Any, **kwargs) -> Dict[str, str]:
        """Call LLM to generate search query and justification
        
        Args:
            input_data: string or dictionary containing title and content
            **kwargs: additional parameters
            
        Returns:
            Dictionary containing search_query and reasoning"""
        try:
            if not self.validate_input(input_data):
                raise ValueError("The input data format is wrong and needs to include title and content fields.")
            
            # Prepare to enter data
            if isinstance(input_data, str):
                message = input_data
            else:
                message = json.dumps(input_data, ensure_ascii=False)
            
            logger.info("Generating first search query")
            
            # Call LLM
            response = self.llm_client.stream_invoke_to_string(SYSTEM_PROMPT_FIRST_SEARCH, message)
            
            # Handle response
            processed_response = self.process_output(response)
            
            logger.info(f"Generate search query: {processed_response.get('search_query', 'N/A')}")
            return processed_response
            
        except Exception as e:
            logger.exception(f"Failed to generate first search query: {str(e)}")
            raise e
    
    def process_output(self, output: str) -> Dict[str, str]:
        """Process LLM output, extract search queries and inference
        
        Args:
            output: LLM raw output
            
        Returns:
            Dictionary containing search_query and reasoning"""
        try:
            # Clean response text
            cleaned_output = remove_reasoning_from_output(output)
            cleaned_output = clean_json_tags(cleaned_output)
            
            # Logging cleaned output for debugging
            logger.info(f"Cleaned output: {cleaned_output}")
            
            # Parse JSON
            try:
                result = json.loads(cleaned_output)
                logger.info("JSON parsed successfully")
            except JSONDecodeError as e:
                logger.error(f"JSON parsing failed: {str(e)}")
                # Use more powerful extraction methods
                result = extract_clean_response(cleaned_output)
                if "error" in result:
                    logger.error("JSON parsing failed, trying to fix...")
                    # Try to fix JSON
                    fixed_json = fix_incomplete_json(cleaned_output)
                    if fixed_json:
                        try:
                            result = json.loads(fixed_json)
                            logger.info("JSON repair successful")
                        except JSONDecodeError:
                            logger.error("JSON repair failed")
                            # Return to default query
                            return self._get_default_search_query()
                    else:
                        logger.error("Unable to fix JSON, using default query")
                        return self._get_default_search_query()
            
            # Validate and clean results
            search_query = result.get("search_query", "")
            reasoning = result.get("reasoning", "")
            
            if not search_query:
                logger.warning("Search query not found, using default query")
                return self._get_default_search_query()
            
            return {
                "search_query": search_query,
                "reasoning": reasoning
            }
            
        except Exception as e:
            self.log_error(f"Failed to process output: {str(e)}")
            # Return to default query
            return self._get_default_search_query()
    
    def _get_default_search_query(self) -> Dict[str, str]:
        """Get default search query
        
        Returns:
            Default search query dictionary"""
        return {
            "search_query": "Research on related topics",
            "reasoning": "Use default search query due to parsing failure"
        }


class ReflectionNode(BaseNode):
    """Nodes that reflect on paragraphs and generate new search queries"""
    
    def __init__(self, llm_client):
        """Initialize reflection node
        
        Args:
            llm_client: LLM client"""
        super().__init__(llm_client, "ReflectionNode")
    
    def validate_input(self, input_data: Any) -> bool:
        """Validate input data"""
        if isinstance(input_data, str):
            try:
                data = json.loads(input_data)
                required_fields = ["title", "content", "paragraph_latest_state"]
                return all(field in data for field in required_fields)
            except JSONDecodeError:
                return False
        elif isinstance(input_data, dict):
            required_fields = ["title", "content", "paragraph_latest_state"]
            return all(field in input_data for field in required_fields)
        return False
    
    def run(self, input_data: Any, **kwargs) -> Dict[str, str]:
        """Call LLM to reflect and generate search queries
        
        Args:
            input_data: string or dictionary containing title, content and paragraph_latest_state
            **kwargs: additional parameters
            
        Returns:
            Dictionary containing search_query and reasoning"""
        try:
            if not self.validate_input(input_data):
                raise ValueError("The input data format is wrong and needs to contain the title, content and paragraph_latest_state fields.")
            
            # Prepare to enter data
            if isinstance(input_data, str):
                message = input_data
            else:
                message = json.dumps(input_data, ensure_ascii=False)
            
            logger.info("Reflection in progress and new search query generated")
            
            # Call LLM
            response = self.llm_client.stream_invoke_to_string(SYSTEM_PROMPT_REFLECTION, message)
            
            # Handle response
            processed_response = self.process_output(response)
            
            logger.info(f"Reflection generates search query: {processed_response.get('search_query', 'N/A')}")
            return processed_response
            
        except Exception as e:
            logger.exception(f"Reflection failed to generate search query: {str(e)}")
            raise e
    
    def process_output(self, output: str) -> Dict[str, str]:
        """Process LLM output, extract search queries and inference
        
        Args:
            output: LLM raw output
            
        Returns:
            Dictionary containing search_query and reasoning"""
        try:
            # Clean response text
            cleaned_output = remove_reasoning_from_output(output)
            cleaned_output = clean_json_tags(cleaned_output)
            
            # Logging cleaned output for debugging
            logger.info(f"Cleaned output: {cleaned_output}")
            
            # Parse JSON
            try:
                result = json.loads(cleaned_output)
                logger.info("JSON parsed successfully")
            except JSONDecodeError as e:
                logger.error(f"JSON parsing failed: {str(e)}")
                # Use more powerful extraction methods
                result = extract_clean_response(cleaned_output)
                if "error" in result:
                    logger.error("JSON parsing failed, trying to fix...")
                    # Try to fix JSON
                    fixed_json = fix_incomplete_json(cleaned_output)
                    if fixed_json:
                        try:
                            result = json.loads(fixed_json)
                            logger.info("JSON repair successful")
                        except JSONDecodeError:
                            logger.error("JSON repair failed")
                            # Return to default query
                            return self._get_default_reflection_query()
                    else:
                        logger.error("Unable to fix JSON, using default query")
                        return self._get_default_reflection_query()
            
            # Validate and clean results
            search_query = result.get("search_query", "")
            reasoning = result.get("reasoning", "")
            
            if not search_query:
                logger.warning("Search query not found, using default query")
                return self._get_default_reflection_query()
            
            return {
                "search_query": search_query,
                "reasoning": reasoning
            }
            
        except Exception as e:
            logger.exception(f"Failed to process output: {str(e)}")
            # Return to default query
            return self._get_default_reflection_query()
    
    def _get_default_reflection_query(self) -> Dict[str, str]:
        """Get the default reflection search query
        
        Returns:
            Default reflective search query dictionary"""
        return {
            "search_query": "Additional information for in-depth research",
            "reasoning": "Using default reflection search query due to parsing failure"
        }
