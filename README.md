<div align="center">

<img src="static/image/logo_compressed.png" alt="BettaFish Logo" width="100%">

<a href="https://trendshift.io/repositories/15286" target="_blank"><img src="https://trendshift.io/api/badge/repositories/15286" alt="666ghj%2FBettaFish | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/></a>

<a href="https://aihubmix.com/?aff=8Ds9" target="_blank"><img src="./static/image/logo_aihubmix.png" alt="666ghj%2FBettaFish | Trendshift" height="40"/></a>&ensp;
<a href="https://open.anspire.cn/?share_code=3E1FUOUH" target="_blank"><img src="./static/image/logo_anspire.png" alt="666ghj%2FBettaFish | Trendshift" height="40"/></a>&ensp;
<a href="https://www.thordata.com/?ls=github&lk=BettaFish" target="_blank"><img src="./static/image/logo_thordata.png" alt="666ghj%2FBettaFish | Trendshift" height="40"/></a>

[![GitHub Stars](https://img.shields.io/github/stars/666ghj/BettaFish?style=flat-square)](https://github.com/666ghj/BettaFish/stargazers)
[![GitHub Watchers](https://img.shields.io/github/watchers/666ghj/BettaFish?style=flat-square)](https://github.com/666ghj/BettaFish/watchers)
[![GitHub Forks](https://img.shields.io/github/forks/666ghj/BettaFish?style=flat-square)](https://github.com/666ghj/BettaFish/network)
[![GitHub Issues](https://img.shields.io/github/issues/666ghj/BettaFish?style=flat-square)](https://github.com/666ghj/BettaFish/issues)
[![GitHub Pull Requests](https://img.shields.io/github/issues-pr/666ghj/BettaFish?style=flat-square)](https://github.com/666ghj/BettaFish/pulls)

[![GitHub License](https://img.shields.io/github/license/666ghj/BettaFish?style=flat-square)](https://github.com/666ghj/BettaFish/blob/main/LICENSE)
[![Version](https://img.shields.io/badge/version-v1.2.1-green.svg?style=flat-square)](https://github.com/666ghj/BettaFish)
[![Docker](https://img.shields.io/badge/Docker-Build-2496ED?style=flat-square&logo=docker&logoColor=white)](https://hub.docker.com/)



[English](./README-EN.md) | [Chinese Document](./README.md)

</div>

## ‚ö° Project Overview

"**Weiyu**" is an innovative multi-agent public opinion analysis system implemented from scratch to help everyone break out of the information cocoon, restore the original appearance of public opinion, predict future trends, and assist decision-making. Users only need to put forward analysis requirements like chatting, and the agent will start to fully automatically analyze 30+ domestic and foreign mainstream social media and millions of public comments.

> "Weiyu" is homophonic to "micro fish". BettaFish is a small but very aggressive and beautiful fish. It symbolizes "small but powerful, not afraid of challenges"

View the research report generated by the system using "Wuhan University Public Opinion" as an example: [Wuhan University Brand Reputation In-depth Analysis Report](./final_reports/final_report__20250827_131630.html)

Check out the video of a complete operation of the system using "Public Opinion of Wuhan University" as an example: [Video - In-depth Analysis Report on Wuhan University Brand Reputation](https://www.bilibili.com/video/BV1TH1WBxEWN/?vd_source=da3512187e242ce17dceee4c537ec7a6#reply279744466833)

Not only reflected in the quality of the report, compared with similar products, we have six major advantages:

1. **AI-driven global monitoring**: The AI ‚Äã‚Äãcrawler cluster operates 24/7, fully covering 10+ key domestic and foreign social media such as Weibo, Xiaohongshu, Douyin, and Kuaishou. It not only captures hot content in real time, but also drills down to massive user comments, allowing you to hear the most authentic and broad public voices.

2. **Compound analysis engine beyond LLM**: We not only rely on the designed five types of professional Agents, but also integrate fine-tuning models, statistical models and other middleware. Through the collaborative work of multiple models, the depth, accuracy and multi-dimensional perspective of the analysis results are ensured.

3. **Powerful multi-modal capabilities**: Breaking through the limitations of graphics and text, it can deeply analyze short video content such as Douyin and Kuaishou, and accurately extract structured multi-modal information cards such as weather, calendar, and stocks in modern search engines, allowing you to fully grasp the dynamics of public opinion.

4. **Agent "Forum" collaboration mechanism**: Give different Agents unique toolsets and thinking modes, introduce a debate moderator model, and conduct chain thinking collisions and debates through the "Forum" mechanism. This not only avoids the limitations of thinking and homogeneity caused by communication of a single model, but also produces higher-quality collective intelligence and decision support.

5. **Seamless integration of public and private domain data**: The platform not only analyzes public public opinion, but also provides a high-security interface to support you to seamlessly integrate your internal business database with public opinion data. Break through data barriers and provide powerful analysis capabilities of "external trends + internal insights" for vertical businesses.

6. **Lightweight and highly scalable framework**: Based on pure Python modular design, it achieves lightweight and one-click deployment. The code structure is clear, and developers can easily integrate custom models and business logic to achieve rapid expansion and in-depth customization of the platform.

**Starts from public opinion, not just public opinion**. The goal of "Weiyu" is to become a simple and universal data analysis engine that drives all business scenarios.

> For example. You can turn it into a market analysis system in the financial field by simply modifying the API parameters and prompts of the Agent tool set.
>
> Attached is a relatively active L station project discussion thread: https://linux.do/t/topic/1009280
>
> View the evaluation done by friends from L station [Comparison between open source project (Weiyu) and manus|minimax|ChatGPT](https://linux.do/t/topic/1148040)

<div align="center">
<img src="static/image/system_schematic.png" alt="banner" width="800">

Say goodbye to traditional data dashboards. In "Weiyu", everything starts with a simple question. You just need to put forward your analysis needs like a conversation.
</div>

## ü™Ñ Sponsor

LLM model API sponsorship: <a href="https://aihubmix.com/?aff=8Ds9" target="_blank"><img src="./static/image/logo_aihubmix.png" alt="666ghj%2FBettaFish | Trendshift" height="40"/></a>

<details>
<summary>Provider of AI core capabilities such as Internet search, file parsing and web content crawling:</a><span style="margin-left: 10px"><a href="https://open.anspire.cn/?share_code=3E1FUOUH" target="_blank"><img src="./static/image/logo_anspire.png" alt="666ghj%2FBettaFish | Trendshift" height="50"/></a></summary>
Anspire Open is a leading infrastructure provider for the era of intelligent agents. We provide developers with the core capability stack required to build powerful agents. We have now launched services such as AI network search [multiple versions, very competitive prices], file analysis [free for a limited time] and web content capture [free for a limited time], cloud browser automation (Anspire Browser Agent) [internal testing], multiple rounds of rewriting and other services, continuing to provide a solid foundation for intelligent agents to connect and operate in the complex digital world. It can be seamlessly integrated into mainstream intelligent agent platforms such as Dify, Coze, and Yuanqi. Through the transparent point billing system and modular design, it provides enterprises with efficient, low-cost customized support and accelerates the intelligent upgrade process.
</details>

<details>
<summary>Get a free 1GB free trial, enterprise-level global proxy IP and Scraper API solution provider, register now:</a><span style="margin-left: 10px"><a href="https://www.thordata.com/?ls=github&lk=BettaFish" target="_blank"><img src="./static/image/logo_thordata.png" alt="666ghj%2FBettaFish | Trendshift" height="40"/></a></summary>
<img src="static/image/banner_thordata.png" height="250" alt="banner">
Thordata helps enterprises easily obtain public network data through a highly reliable proxy network and automated crawling solutions, and promises an uptime of 99.9% and a success rate of 99.7%.
</details>

## üèóÔ∏è System architecture

### Overall architecture diagram

**Insight Agent** Private database mining: in-depth analysis of private public opinion database AI agent

**Media Agent** Multi-modal content analysis: AI agent with powerful multi-modal capabilities

**Query Agent** Precise information search: AI agent with domestic and foreign web page search capabilities

**Report Agent** Intelligent report generation: multi-round report generation AI agent with built-in templates

<div align="center">
<img src="static/image/framework.png" alt="banner" width="800">
</div>

### A complete analysis process

| Steps | Phase Name | Main Operations | Participating Components | Loop Features |
|------|----------|----------|----------|----------|
| 1 | User question | Flask main application receives query | Flask main application | - |
| 2 | Parallel startup | Three Agents start working at the same time | Query Agent, Media Agent, Insight Agent | - |
| 3 | Preliminary analysis | Each Agent uses exclusive tools for overview search | Each Agent + exclusive tool set | - |
| 4 | Strategy formulation | Formulate segmented research strategies based on preliminary results | Internal decision-making module of each Agent | - |
| 5-N | **Cycle Phase** | **Forum Collaboration + In-depth Research** | **ForumEngine + All Agents** | **Multiple Cycles** |
| 5.1 | In-depth research | Each Agent conducts special searches based on the guidance of the forum host | Each Agent + reflection mechanism + forum guidance | Each round of circulation |
| 5.2 | Forum collaboration | ForumEngine monitors Agent's speech and generates moderator guidance | ForumEngine + LLM moderator | Each round cycle |
| 5.3 | Communication and integration | Each Agent adjusts the research direction according to the discussion | Each Agent + forum_reader tool | Each round of circulation |
| N+1 | Result integration | Report Agent collects all analysis results and forum content | Report Agent | - |
| N+2 | IR intermediate representation | Dynamically select templates and styles, generate metadata in multiple rounds, and bind it into IR intermediate representation | Report Agent + Template Engine | - |
| N+3 | Report generation | Perform quality inspection in chunks and render an interactive HTML report based on IR | Report Agent + binding engine | - |

### Project code structure tree

```
BettaFish/
‚îú‚îÄ‚îÄ QueryEngine/ # Domestic and foreign news breadth search agent
‚îÇ ‚îú‚îÄ‚îÄ agent.py # Agent main logic, coordinating the search and analysis process
‚îÇ ‚îú‚îÄ‚îÄ llms/ # LLM interface encapsulation
‚îÇ ‚îú‚îÄ‚îÄ nodes/ # Processing nodes: search, formatting, summary, etc.
‚îÇ ‚îú‚îÄ‚îÄ tools/ # Domestic and foreign news search tool set
‚îÇ ‚îú‚îÄ‚îÄ utils/ # Utility function
‚îÇ ‚îú‚îÄ‚îÄ state/ # State management
‚îÇ ‚îú‚îÄ‚îÄ prompts/ # prompt word template
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ MediaEngine/ # Powerful multi-modal understanding agent
‚îÇ ‚îú‚îÄ‚îÄ agent.py # Agent main logic, processing multi-modal content such as videos/pictures
‚îÇ ‚îú‚îÄ‚îÄ llms/ # LLM interface encapsulation
‚îÇ ‚îú‚îÄ‚îÄ nodes/ # Processing nodes: search, formatting, summary, etc.
‚îÇ ‚îú‚îÄ‚îÄ tools/ # Multimodal search toolset
‚îÇ ‚îú‚îÄ‚îÄ utils/ # Utility function
‚îÇ ‚îú‚îÄ‚îÄ state/ # State management
‚îÇ ‚îú‚îÄ‚îÄ prompts/ # prompt word template
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ InsightEngine/ # Private database mining agent
‚îÇ ‚îú‚îÄ‚îÄ agent.py # Agent main logic, coordinates database query and analysis
‚îÇ ‚îú‚îÄ‚îÄ llms/ # LLM interface encapsulation
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ base.py # Unified OpenAI compatible client
‚îÇ ‚îú‚îÄ‚îÄ nodes/ # Processing nodes: search, formatting, summary, etc.
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ base_node.py #Basic node class
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ search_node.py # Search node
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ formatting_node.py # Formatting node
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ report_structure_node.py # Report structure node
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ summary_node.py # Summary node
‚îÇ ‚îú‚îÄ‚îÄ tools/ # Database query and analysis toolset
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ keyword_optimizer.py # Qwen keyword optimization middleware
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ search.py ‚Äã‚Äã# Database operation toolset (topic search, comment acquisition, etc.)
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ sentiment_analyzer.py # Sentiment analysis integration tool
‚îÇ ‚îú‚îÄ‚îÄ utils/ # Utility function
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ config.py # Configuration management
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ db.py # SQLAlchemy asynchronous engine and read-only query encapsulation
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ text_processing.py # Text processing tool
‚îÇ ‚îú‚îÄ‚îÄ state/ # State management
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ state.py # Agent state definition
‚îÇ ‚îú‚îÄ‚îÄ prompts/ # prompt word template
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ prompts.py # Various prompt words
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ ReportEngine/ # Multi-round report generation Agent
‚îÇ ‚îú‚îÄ‚îÄ agent.py # Overall scheduler: Template selection‚ÜíLayout‚ÜíLength‚ÜíChapter‚ÜíRendering
‚îÇ ‚îú‚îÄ‚îÄ flask_interface.py # Flask/SSE entrance, management task queuing and streaming events
‚îÇ ‚îú‚îÄ‚îÄ llms/ # OpenAI compatible LLM package
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ base.py # Unified streaming/retry client
‚îÇ ‚îú‚îÄ‚îÄ core/ # Core functions: template parsing, chapter storage, document binding
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ template_parser.py # Markdown template slicing and slug generation
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ chapter_storage.py # Chapter run directory, manifest and raw stream writing
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ stitcher.py # Document IR stitcher, complete anchor points/metadata
‚îÇ ‚îú‚îÄ‚îÄ ir/ # Report intermediate representation (IR) contract and verification
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ schema.py # Block/mark Schema constant definition
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ validator.py # Chapter JSON structure validator
‚îÇ ‚îú‚îÄ‚îÄ nodes/ # Full process reasoning node
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ base_node.py # Node base class + log/status hook
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ template_selection_node.py # Template candidate collection and LLM screening
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ document_layout_node.py # Title/Table of Contents/Theme Design
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ word_budget_node.py # Space planning and chapter command generation
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ chapter_generation_node.py # Chapter-level JSON generation + verification
‚îÇ ‚îú‚îÄ‚îÄ prompts/ # Prompt dictionary and Schema description
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ prompts.py # Template selection/layout/length/chapter prompts
‚îÇ ‚îú‚îÄ‚îÄ renderers/ # IR renderer
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ html_renderer.py # Document IR‚ÜíInteractive HTML
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ pdf_renderer.py # HTML‚ÜíPDF export (WeasyPrint)
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ pdf_layout_optimizer.py # PDF layout optimizer
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ chart_to_svg.py # Chart to SVG tool
‚îÇ ‚îú‚îÄ‚îÄ state/ # Task/metadata state model
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ state.py # ReportState and serialization tools
‚îÇ ‚îú‚îÄ‚îÄ utils/ # Configuration and auxiliary tools
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ config.py # Pydantic Settings and printing assistant
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ dependency_check.py # Dependency checking tool
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ json_parser.py # JSON parsing tool
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ chart_validator.py # Chart verification tool
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ chart_repair_api.py # Chart repair API
‚îÇ ‚îú‚îÄ‚îÄ report_template/ # Markdown template library
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ Corporate Brand Reputation Analysis Report.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ ForumEngine/ # Forum engine: Agent collaboration mechanism
‚îÇ ‚îú‚îÄ‚îÄ monitor.py # Log monitoring and forum management core
‚îÇ ‚îú‚îÄ‚îÄ llm_host.py # Forum host LLM module
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ MindSpider/ #Social media crawler system
‚îÇ ‚îú‚îÄ‚îÄ main.py # Crawler main program entrance
‚îÇ ‚îú‚îÄ‚îÄ config.py # Crawler configuration file
‚îÇ ‚îú‚îÄ‚îÄ BroadTopicExtraction/ # Topic extraction module
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ main.py # Topic extraction main program
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ database_manager.py # Database manager
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ get_today_news.py # Get today‚Äôs news
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ topic_extractor.py # Topic extractor
‚îÇ ‚îú‚îÄ‚îÄ DeepSentimentCrawling/ # Deep public opinion crawling module
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ main.py # Deep crawling main program
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ keyword_manager.py # Keyword manager
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ platform_crawler.py # Platform crawler management
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ MediaCrawler/ # Social media crawler core
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ main.py
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ config/ # Configuration for each platform
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ media_platform/ # Implementation of crawlers on each platform
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îÇ ‚îî‚îÄ‚îÄ schema/ # Database structure definition
‚îÇ ‚îú‚îÄ‚îÄ db_manager.py # Database manager
‚îÇ ‚îú‚îÄ‚îÄ init_database.py # Database initialization script
‚îÇ ‚îú‚îÄ‚îÄ mindspider_tables.sql # Database table structure SQL
‚îÇ ‚îú‚îÄ‚îÄ models_bigdata.py # SQLAlchemy mapping of large-scale media public opinion tables
‚îÇ ‚îî‚îÄ‚îÄ models_sa.py # DailyTopic/Task and other extended table ORM models
‚îú‚îÄ‚îÄ SentimentAnalysisModel/ # Sentiment analysis model collection
‚îÇ ‚îú‚îÄ‚îÄ WeiboSentiment_Finetuned/ # Fine-tuning the BERT/GPT-2 model
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ BertChinese-Lora/ # BERT Chinese LoRA fine-tuning
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predict.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ GPT2-Lora/ # GPT-2 LoRA fine-tuning
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ predict.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îÇ ‚îú‚îÄ‚îÄ WeiboMultilingualSentiment/ # Multilingual Sentiment Analysis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predict.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ ‚îú‚îÄ‚îÄ WeiboSentiment_SmallQwen/ # Small parameter Qwen3 fine-tuning
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predict_universal.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ ‚îî‚îÄ‚îÄ WeiboSentiment_MachineLearning/ # Traditional machine learning method
‚îÇ       ‚îú‚îÄ‚îÄ train.py
‚îÇ       ‚îú‚îÄ‚îÄ predict.py
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ SingleEngineApp/ # Streamlit application of a single agent
‚îÇ ‚îú‚îÄ‚îÄ query_engine_streamlit_app.py # QueryEngine stand-alone application
‚îÇ ‚îú‚îÄ‚îÄ media_engine_streamlit_app.py # MediaEngine standalone application
‚îÇ ‚îî‚îÄ‚îÄ insight_engine_streamlit_app.py # InsightEngine stand-alone application
‚îú‚îÄ‚îÄ query_engine_streamlit_reports/ # QueryEngine single application operation output
‚îú‚îÄ‚îÄ media_engine_streamlit_reports/ # MediaEngine single application operation output
‚îú‚îÄ‚îÄ insight_engine_streamlit_reports/ # InsightEngine single application operation output
‚îú‚îÄ‚îÄ templates/ # Flask front-end template
‚îÇ ‚îî‚îÄ‚îÄ index.html # Main interface HTML
‚îú‚îÄ‚îÄ static/ # Static resources
‚îÇ ‚îî‚îÄ‚îÄ image/ # Image resources
‚îÇ       ‚îú‚îÄ‚îÄ logo_compressed.png
‚îÇ       ‚îú‚îÄ‚îÄ framework.png
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ logs/ # Run log directory
‚îú‚îÄ‚îÄ final_reports/ # The final generated report file
‚îÇ ‚îú‚îÄ‚îÄ ir/ # Report IR JSON file
‚îÇ ‚îî‚îÄ‚îÄ *.html # Final HTML report
‚îú‚îÄ‚îÄ utils/ # General utility function
‚îÇ ‚îú‚îÄ‚îÄ forum_reader.py # Forum communication tool between agents
‚îÇ ‚îú‚îÄ‚îÄ github_issues.py # Generate GitHub Issue links and error messages in a unified manner
‚îÇ ‚îî‚îÄ‚îÄ retry_helper.py # Network request retry mechanism tool
‚îú‚îÄ‚îÄ tests/ # Unit testing and integration testing
‚îÇ ‚îú‚îÄ‚îÄ run_tests.py # pytest entry script
‚îÇ ‚îú‚îÄ‚îÄ test_monitor.py # ForumEngine monitoring unit test
‚îÇ ‚îú‚îÄ‚îÄ test_report_engine_sanitization.py # ReportEngine security test
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ app.py # Flask main application entrance
‚îú‚îÄ‚îÄ config.py # Global configuration file
‚îú‚îÄ‚îÄ .env.example # Environment variable example file
‚îú‚îÄ‚îÄ docker-compose.yml # Docker multi-service orchestration configuration
‚îú‚îÄ‚îÄ Dockerfile # Docker image build file
‚îú‚îÄ‚îÄ requirements.txt # Python dependency package list
‚îú‚îÄ‚îÄ regenerate_latest_html.py # Rebind and render HTML using the latest chapter
‚îú‚îÄ‚îÄ regenerate_latest_md.py # Use the latest chapter to rebind and render Markdown
‚îú‚îÄ‚îÄ regenerate_latest_pdf.py # PDF regeneration tool script
‚îú‚îÄ‚îÄ report_engine_only.py # Report Engine command line version
‚îú‚îÄ‚îÄ README.md # Chinese documentation
‚îú‚îÄ‚îÄ README-EN.md # English documentation
‚îú‚îÄ‚îÄ CONTRIBUTING.md # Chinese Contribution Guide
‚îú‚îÄ‚îÄ CONTRIBUTING-EN.md # English Contribution Guide
‚îî‚îÄ‚îÄ LICENSE # GPL-2.0 Open Source License
```

## üöÄ Quick Start (Docker)

### 1. Start the project

Copy a copy of the `.env.example` file, name it `.env`, and configure the environment variables in the `.env` file as needed

Execute the following command to start all services in the background:

```bash
docker compose up -d
```

> **Note: The image pulling speed is slow**. In the original `docker-compose.yml` file, we have provided an alternate image address for your replacement through **comments**

### 2. Configuration instructions

#### Database configuration (PostgreSQL)

Please configure the database connection information according to the following parameters. Mysql is also supported and can be modified by yourself:

| Configuration item | Fill in the value | Description |
| :--- | :--- | :--- |
| `DB_HOST` | `db` | Database service name (corresponding to the service name in `docker-compose.yml`) |
| `DB_PORT` | `5432` | Default PostgreSQL port |
| `DB_USER` | `bettafish` | Database username |
| `DB_PASSWORD` | `bettafish` | Database password |
| `DB_NAME` | `bettafish` | Database name |
| **Others** | **Keep default** | Please keep the default settings for other parameters such as database connection pool. |

#### Large model configuration

> All our LLM calls use OpenAI‚Äôs API interface standards

After completing the database configuration, please configure **all large model-related parameters** normally to ensure that the system can connect to the large model service you selected.

After all the above configurations are completed and saved, the system can run normally.

## üîß Source code startup guide

> If you are learning to build an Agent system for the first time, you can start with a very simple demo: [Deep Search Agent Demo](https://github.com/666ghj/DeepSearchAgent-Demo)

### Environmental requirements

- **Operating System**: Windows, Linux, MacOS
- **Python version**: 3.9+
- **Conda**: Anaconda or Miniconda
- **Database**: PostgreSQL (recommended) or MySQL
- **Memory**: 2GB or more recommended

### 1. Create environment

#### If using Conda

```bash
#Create conda environment
conda create -n your_conda_name python=3.11
conda activate your_conda_name
```

#### If using uv

```bash
#Create uv environment
uv venv --python 3.11 # Create a 3.11 environment
```

### 2. Install the system dependencies required for PDF export (optional)

This part has detailed configuration instructions: [Configuration required dependencies](./static/Partial%20README%20for%20PDF%20Exporting/README.md)

### 3. Install dependency packages

> If step 2 is skipped, the weasyprint library may not be installed and the PDF function may not work properly.

```bash
#Basic dependency installation
pip install -r requirements.txt

#uv version command (faster installation)
uv pip install -r requirements.txt
# If you do not want to use the local sentiment analysis model (the computing power requirement is very small, the cpu version is installed by default), you can comment out the "machine learning" part of the file and then execute the instructions
```

### 4. Install Playwright browser driver

```bash
# Install browser driver (for crawler function)
playwright install chromium
```

### 5. Configure LLM and database

Copy the `.env.example` file in the project root directory and name it `.env`

Edit the `.env` file and fill in your API key (you can also choose your own model and search agent. For details, see the instructions in the root directory .env.example file or the root directory config.py):

```yml
# ====================== Database configuration ======================
# Database host, such as localhost or 127.0.0.1
DB_HOST=your_db_host
# Database port number, default is 3306
DB_PORT=3306
# Database username
DB_USER=your_db_user
# Database password
DB_PASSWORD=your_db_password
# Database name
DB_NAME=your_db_name
# Database character set, utf8mb4 is recommended, compatible with emoji
DB_CHARSET=utf8mb4
# Database type postgresql or mysql
DB_DIALECT=postgresql
# The database does not need to be initialized and will be automatically detected when executing app.py

# ====================== LLM configuration ======================
# You can change the API used by each part of LLM, as long as it is compatible with the OpenAI request format
# The recommended LLM for each Agent is given in the configuration file. Please refer to the recommended settings for initial deployment.

# Insight Agent
INSIGHT_ENGINE_API_KEY=
INSIGHT_ENGINE_BASE_URL=
INSIGHT_ENGINE_MODEL_NAME=

# Media Agent
...
```

### 6. Start the system

#### 6.1 Complete system startup (recommended)

```bash
# In the project root directory, activate the conda environment
conda activate your_conda_name

# Just start the main application
python app.py
```

uv version startup command
```bash
# In the project root directory, activate the uv environment
.venv\Scripts\activate

# Just start the main application
python app.py
```

> Note 1: After a run is terminated, the streamlit app may end abnormally and still occupy the port. At this time, search for the process occupying the port and kill it.

> Note 2: Data crawling requires separate operations, see 6.3 Guidelines

Visit http://localhost:5000 to use the complete system

#### 6.2 Start an Agent individually

```bash
# Start QueryEngine
streamlit run SingleEngineApp/query_engine_streamlit_app.py --server.port 8503

# Start MediaEngine
streamlit run SingleEngineApp/media_engine_streamlit_app.py --server.port 8502

# Start InsightEngine
streamlit run SingleEngineApp/insight_engine_streamlit_app.py --server.port 8501
```

#### 6.3 The crawler system is used alone

This part has detailed configuration documents: [MindSpider Instructions for Use](./MindSpider/README.md)

<div align="center">
<img src="MindSpider\img\example.png" alt="banner" width="600">

MindSpider running example
</div>

```bash
# Enter the crawler directory
cd MindSpider

#Project initialization
python main.py --setup

# Run topic extraction (get hot news and keywords)
python main.py --broad-topic

# Run the complete crawler process
python main.py --complete --date 2024-01-20

# Run topic extraction only
python main.py --broad-topic --date 2024-01-20

# Run deep crawl only
python main.py --deep-sentiment --platforms xhs dy wb
```

#### 6.4 Command line report generation tool

The tool skips the running phase of the three analysis engines, directly reads their latest log files, and generates a comprehensive report without the need for a web interface (while omitting the file incremental verification step), and automatically generates Markdown after the PDF by default (available parameters are turned off). Typically used when the report generation results are not satisfactory, a quick retry is required, or when debugging the Report Engine.

```bash
#Basic usage (automatically extract themes from file names)
python report_engine_only.py

#Specify report topic
python report_engine_only.py --query "Civil Engineering Industry Analysis"

# Skip PDF generation (even if the system supports it)
python report_engine_only.py --skip-pdf

# Skip Markdown generation
python report_engine_only.py --skip-markdown

# Show detailed logs
python report_engine_only.py --verbose

# View help information
python report_engine_only.py --help
```

**Function Description:**

1. **Automatically check dependencies**: The program will automatically check the system dependencies required for PDF generation, and will give an installation prompt if they are missing.
2. **Get the latest files**: Automatically get the latest analysis reports from the three engine directories (`insight_engine_streamlit_reports`, `media_engine_streamlit_reports`, `query_engine_streamlit_reports`)
3. **File Confirmation**: Display all selected file names, paths and modification times, waiting for user confirmation (default input `y` to continue, enter `n` to exit)
4. **Generate reports directly**: Skip the file addition review process and directly call the Report Engine to generate a comprehensive report
5. **Automatically save files**:
- HTML reports are saved to the `final_reports/` directory
- PDF reports (if dependent) are saved to the `final_reports/pdf/` directory
- Markdown reports (can be turned off with `--skip-markdown`) are saved to the `final_reports/md/` directory
- File naming format: `final_report_{topic}_{timestamp}.html/pdf/md`

**Note:**

- Make sure at least one of the three engine directories contains a `.md` report file
- The command line tool and the web interface are independent of each other and will not affect each other.
- PDF generation requires the installation of system dependencies. For details, see the "Installing System Dependencies Required for PDF Export" section above.

**Fast re-rendering of latest results:**

- `regenerate_latest_html.py` / `regenerate_latest_md.py`: Rebase the Document IR from the latest chapter JSON run in `CHAPTER_OUTPUT_DIR` and render HTML or Markdown directly.
- `regenerate_latest_pdf.py`: Read the latest IR in `final_reports/ir` and re-export PDF using SVG vector chart.

## ‚öôÔ∏è Advanced configuration (outdated, has been unified into project root directory .env file management, other sub-agents automatically inherit the root directory configuration)

### Modify key parameters

#### Agent configuration parameters

Each Agent has a dedicated configuration file that can be adjusted according to needs. Here are some examples:

```python
# QueryEngine/utils/config.py
class Config:
max_reflections = 2 # Reflection rounds
max_search_results = 15 # Maximum number of search results
max_content_length = 8000 # Maximum content length
    
# MediaEngine/utils/config.py  
class Config:
comprehensive_search_limit = 10 # Comprehensive search limit
web_search_limit = 15 # Web search limit
    
# InsightEngine/utils/config.py
class Config:
default_search_topic_globally_limit = 200 # Global search limit
default_get_comments_limit = 500 # Comment retrieval limit
max_search_results_for_llm = 50 # Maximum number of results passed to LLM
```

#### Sentiment analysis model configuration

```python
# InsightEngine/tools/sentiment_analyzer.py
SENTIMENT_CONFIG = {
'model_type': 'multilingual', # Optional: 'bert', 'multilingual', 'qwen', etc.
'confidence_threshold': 0.8, # Confidence threshold
'batch_size': 32, # Batch size
'max_sequence_length': 512, # Maximum sequence length
}
```

### Access different LLM models

LLM providers that support any openAI calling format only need to fill in the corresponding KEY, BASE_URL, and MODEL_NAME in /config.py.

> What is the openAI calling format? A simple example is provided below:
>```python
>from openai import OpenAI
>
>client = OpenAI(api_key="your_api_key", 
>                base_url="https://aihubmix.com/v1")
>
>response = client.chat.completions.create(
>    model="gpt-4o-mini",
>    messages=[
>        {'role': 'user', 
> 'content': "What new opportunities will the inference model bring to the market?"}
>    ],
>)
>
>complete_response = response.choices[0].message.content
>print(complete_response)
>```

### Change sentiment analysis model

The system integrates a variety of sentiment analysis methods, which can be selected according to needs:

#### 1. Multi-language sentiment analysis

```bash
cd SentimentAnalysisModel/WeiboMultilingualSentiment
python predict.py --text "This product is amazing!" --lang "en"
```

#### 2. Small parameter Qwen3 fine-tuning

```bash
cd SentimentAnalysisModel/WeiboSentiment_SmallQwen
python predict_universal.py --text "This event was a success"
```

#### 3. Fine-tuning model based on BERT

```bash
# Use BERT Chinese model
cd SentimentAnalysisModel/WeiboSentiment_Finetuned/BertChinese-Lora
python predict.py --text "This product is really good"
```

#### 4. GPT-2 LoRA fine-tuning model

```bash
cd SentimentAnalysisModel/WeiboSentiment_Finetuned/GPT2-Lora
python predict.py --text "I'm not in a good mood today"
```

#### 5. Traditional machine learning methods

```bash
cd SentimentAnalysisModel/WeiboSentiment_MachineLearning
python predict.py --model_type "svm" --text "Service attitude needs improvement"
```

### Access custom business database

#### 1. Modify database connection configuration

```python
#Add your business database configuration in config.py
BUSINESS_DB_HOST = "your_business_db_host"
BUSINESS_DB_PORT = 3306
BUSINESS_DB_USER = "your_business_user"
BUSINESS_DB_PASSWORD = "your_business_password"
BUSINESS_DB_NAME = "your_business_database"
```

#### 2. Create custom data access tools

```python
# InsightEngine/tools/custom_db_tool.py
class CustomBusinessDBTool:
"""Customized business database query tool"""
    
    def __init__(self):
        self.connection_config = {
            'host': config.BUSINESS_DB_HOST,
            'port': config.BUSINESS_DB_PORT,
            'user': config.BUSINESS_DB_USER,
            'password': config.BUSINESS_DB_PASSWORD,
            'database': config.BUSINESS_DB_NAME,
        }
    
    def search_business_data(self, query: str, table: str):
"""Query business data"""
# Implement your business logic
        pass
    
    def get_customer_feedback(self, product_id: str):
"""Get customer feedback data"""
# Implement customer feedback query logic
        pass
```

#### 3. Integrate into InsightEngine

```python
#Integrate custom tools in InsightEngine/agent.py
from .tools.custom_db_tool import CustomBusinessDBTool

class DeepSearchAgent:
    def __init__(self, config=None):
# ...other initialization code
        self.custom_db_tool = CustomBusinessDBTool()
    
    def execute_custom_search(self, query: str):
"""Perform a custom business data search"""
        return self.custom_db_tool.search_business_data(query, "your_table")
```

### Custom report template

#### 1. Upload in the web interface

The system supports uploading custom template files (.md or .txt format), which can be selected for use when generating reports.

#### 2. Create template file

Create a new template in the `ReportEngine/report_template/` directory, and our Agent will select the most appropriate template.

## ü§ù Contribution Guide

We welcome all forms of contributions!

**Please read the following contribution guidelines:**
- [CONTRIBUTING.md](./CONTRIBUTING.md)

## ü¶ñ Next development plan

At present, the system has only completed the first two steps of the "Three Bans", namely: input requirements -> detailed analysis. It still lacks one step of prediction. It is not convincing to directly hand it over to LLM.

<div align="center">
<img src="static/image/banner_compressed.png" alt="banner" width="800">
</div>

At present, after a long period of crawling and collection, we have a large amount of hot data on the trend of topic popularity over time, hot spots, etc. across the entire network, and we have the conditions to develop a prediction model. Our team will use prediction model technologies such as time series models, graph neural networks, and multi-modal fusion to reserve it here to achieve a truly data-driven public opinion prediction function.

## ‚ö†Ô∏è Disclaimer

**Important reminder: This project is for learning, academic research and educational purposes only**

1. **Compliance Statement**:
- All code, tools and functionality in this project are for learning, academic research and educational purposes only
- It is strictly prohibited to use this project for any commercial purposes or profit-making activities
- It is strictly prohibited to use this project for any illegal, illegal or infringing actions on the rights of others

2. **Crawler function disclaimer**:
- The crawler function in the project is only for technical learning and research purposes
- Users must abide by the robots.txt agreement and terms of use of the target website
- Users must abide by relevant laws and regulations and are not allowed to conduct malicious crawling or data abuse
- Any legal consequences arising from the use of the crawler function shall be borne by the user

3. **Data Usage Disclaimer**:
- The data analysis functions involved in the project are for academic research only.
- It is strictly prohibited to use analysis results for business decision-making or profit-making purposes
- Users should ensure the legality and compliance of the analyzed data

4. **Technical Disclaimer**:
- This item is provided "as is" without warranty of any kind, express or implied
- The author is not responsible for any direct or indirect losses caused by the use of this project
- Users should evaluate the suitability and risks of the project themselves

5. **LIMITATION OF LIABILITY**:
- Users should fully understand relevant laws and regulations before using this project
- Users should ensure that their usage complies with local laws and regulations
- Any consequences arising from the use of this project in violation of laws and regulations shall be borne by the user.

**Please read and understand the above disclaimer carefully before using this project. By using this project, you agree to and accept all of the above terms. **

## üìÑ License

This project adopts [GPL-2.0 license](LICENSE). See the LICENSE file for details.

## üéâ Support and Contact

### Get help

FAQ: https://github.com/666ghj/BettaFish/issues/185

- **Project homepage**: [GitHub repository](https://github.com/666ghj/BettaFish)
- **Issue feedback**: [Issues page](https://github.com/666ghj/BettaFish/issues)
- **Feature Suggestions**: [Discussions Page](https://github.com/666ghj/BettaFish/discussions)

### Contact information

- üìß **Email**: hangjiang@bupt.edu.cn

### Business Cooperation

- **Enterprise custom development**
- **Big Data Services**
- **Academic Cooperation**
- **Technical Training**

## üë• Contributor

Thanks to the following outstanding contributors:

[![Contributors](https://contrib.rocks/image?repo=666ghj/BettaFish)](https://github.com/666ghj/BettaFish/graphs/contributors)

## üåü Join the official communication group

<div align="center">
<img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&height=200&section=header&text=Welcome to join our technical exchange QQ group!&fontSize=40&fontAlignY=35&desc=Scan the QR code below to join the group chat&descAlignY=55" alt="Welcome to join our technical exchange QQ group!" style="width:60%; max-width:900px; display:block; margin:0 auto;">
<img src="static/image/QQ_Light_Horizenal.png" alt="BettaFish Technical Exchange Group QR Code" style="width:60%; max-width:360px; display:block; margin:20px auto 0;">
</div>

## üìà Project Statistics

<a href="https://www.star-history.com/#666ghj/BettaFish&type=date&legend=top-left">
 <picture>
   <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=666ghj/BettaFish&type=date&theme=dark&legend=top-left" />
   <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=666ghj/BettaFish&type=date&legend=top-left" />
   <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=666ghj/BettaFish&type=date&legend=top-left" />
 </picture>
</a>

![Alt](https://repobeats.axiom.co/api/embed/e04e3eea4674edc39c148a7845c8d09c1b7b1922.svg "Repobeats analytics image")
